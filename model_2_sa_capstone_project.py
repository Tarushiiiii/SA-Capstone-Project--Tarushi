# -*- coding: utf-8 -*-
"""Model-2 SA Capstone Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C8gaRwEvDnU6pEF2ojFJBGom37oHDBUl

# Set Up
Installing required libraries and dependencies
"""

!pip install pathway bokeh scikit-learn --quiet

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import datetime
from datetime import datetime
import pathway as pw
import bokeh.plotting
import panel as pn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error

"""# Step 1: Importing and Preprocessing the Data"""

df = pd.read_csv('/content/Modified - modified.csv')
df

df.drop("Unnamed: 0", axis=1, inplace=True)

# Combine the 'LastUpdatedDate' and 'LastUpdatedTime' columns into a single datetime column
df['Timestamp'] = pd.to_datetime(df['LastUpdatedDate'] + ' ' + df['LastUpdatedTime'],
                                  format='%d-%m-%Y %H:%M:%S')

df.drop(['LastUpdatedDate', 'LastUpdatedTime'], axis=1, inplace=True)

# Sort the DataFrame by the new 'Timestamp' column and reset the index
df = df.sort_values('Timestamp').reset_index(drop=True)

df

df['VehicleType'] = df['VehicleType'].map({
    "cycle": 1, "bike": 3, "car": 5, "truck": 7
})

df["TrafficConditionNearby"] = df["TrafficConditionNearby"].map({
    "low": 1, "average": 5, "high": 9
})

df["IsSpecialDay"] = df["IsSpecialDay"].astype(int)

df

"""# Model-2 (Demand-Based Price Function)

## Step - 2 (Preparation)
"""
BASE_PRICE = 10

df["Price"] = (
    BASE_PRICE +
    0.5 * BASE_PRICE * np.clip(
        (
            5 * (df["Occupancy"] / df["Capacity"]) +
            0.8 * df["QueueLength"] -
            0.6 * df["TrafficConditionNearby"] +
            2.0 * df["IsSpecialDay"] +
            1.2 * df["VehicleType"]
        ) / 20,
        0, 1
    )
)

"""## Step - 3 (Training the Model)"""

X = df[[
    "Occupancy",
    "QueueLength",
    "TrafficConditionNearby",
    "IsSpecialDay",
    "VehicleType"
]]

y = df["Price"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size = 0.2, random_state = 42
)

model = LinearRegression()
model.fit(X_train, y_train)

"""## Step - 4 (Evaluation)"""

preds = model.predict(X_test)
print("MAE: ", mean_absolute_error(y_test, preds))
print("RMSE: ", mean_squared_error(y_test, preds, squared=False))

print("\nLearned Weights: ")
print(pd.Series(model.coef_, index = X.columns))

"""## Step - 5 (Deploy ML model in Pathway)"""

class ParkingSchema2(pw.Schema):
    Timestamp: str   # Timestamp of the observation (should ideally be in ISO format)
    Occupancy: int   # Number of occupied parking spots
    Capacity: int    # Total parking capacity at the location
    IsSpecialDay: float  # Special Day indication: holiday or other special event
    VehicleType: int  # The type of vehicle: car, truck, bike
    TrafficConditionNearby: int  # Nearby traffic congestion level
    QueueLength: int  # Vehicles waiting for entry

# Model-2 Demand-Based Price Function
# Save the selected columns to a CSV file for streaming or downstream processing
df_stream = df[["Timestamp", "Occupancy", "Capacity", "IsSpecialDay", "VehicleType", "TrafficConditionNearby", "QueueLength" ]].to_csv("parking_stream.csv", index=False)
data = pw.demo.replay_csv("parking_stream.csv", schema=ParkingSchema2, input_rate=1000)

# Define the datetime format to parse the 'Timestamp' column
fmt = "%Y-%m-%d %H:%M:%S"

# Add new columns to the data stream:
# - 't' contains the parsed full datetime
# - 'day' extracts the date part and resets the time to midnight (useful for day-level aggregations)
data_with_time = data.with_columns(
    t = data.Timestamp.dt.strptime(fmt),
)

# ML inference inside Pathway

@pw.udf
def ml_price(o, p, t, s, v):
    return float(model.predict([[o, p, t, s, v]])[0])

data = data.with_columns(
    FinalPrice = ml_price(
        pw.this.Occupancy, 
        pw.this.QueueLength,
        pw.this.TrafficConditionNearby,
        pw.this.IsSpecialDay, 
        pw.this.VehicleType
    )
)

"""## Step - 6 (Visualizaing)"""

# Activate the Panel extension to enable interactive visualizations
pn.extension()

# Define a custom Bokeh plotting function that takes a data source (from Pathway) and returns a figure
def price_plotter(source):
    # Create a Bokeh figure with datetime x-axis
    fig = bokeh.plotting.figure(
        height=400,
        width=800,
        title="Pathway: Demand Based Pricing (Model 2)",
        x_axis_type="datetime",  # Ensure time-based data is properly formatted on the x-axis
    )
    # Plot a line graph showing how the FinalPrice evolves over time
    fig.line("t", "FinalPrice", source=source, line_width=2, color="navy")

    # Overlay red circles at each data point for better visibility
    fig.scatter("t", "FinalPrice", source=source, size=6, color="red")

    return fig

# Use Pathway's built-in .plot() method to bind the data stream (data_with_demand) to the Bokeh plot
# - 'price_plotter' is the rendering function
# - 'sorting_col="t"' ensures the data is plotted in time order
viz = data.plot(price_plotter, sorting_col="t")

# Create a Panel layout and make it servable as a web app
# This line enables the interactive plot to be displayed when the app is served
pn.Column(viz).servable()

"""# Run"""

# Commented out IPython magic to ensure Python compatibility.
# # Start the Pathway pipeline execution in the background
# # - This triggers the real-time data stream processing defined above
# # - %%capture --no-display suppresses output in the notebook interface
# 
# %%capture --no-display
# pw.run()

